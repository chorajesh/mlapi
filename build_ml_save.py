# -*- coding: utf-8 -*-
"""Qloudable_TensorFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u8OT_RGk8oaLjJyQcE0SsWPmoFMH84Up

## Introduction to Deep Learning and Tensorflow with Keras API
Recently I saw a post on the facebook by one of friend and he challenged me.
<br>
1 = 12
<br>
2 = 21
<br>
3 = 30
<br>
10 = 93
<br>
20 = 183
<br>
80 = 723
<br>
54 = 489
<br>
72 = 651
<br>
90 = 813
<br>
36 = ?

<br>
I was not able to answer the question immediately. 
After a while I found out the input number should be multipled by 9 and add 3 gives the result.
<br>
1 = 1*9 + 3
<br>
90 = 90*9 + 3
<br>
The same way 36 = 36*9 + 3.
<br>
So the final answer is 327
Now I can answer for any number just by writing a simple program.
Wait.. How did I achieve the program logic. Because I am basically smart enough to identify these kind
of solutions(just kidding) so I say this is of my natural intelligence.
From now onwards I can do the calculation for any input number, because I was trained for the above set of
input and output values.
To make my job easy I wrote a program using simple python as mentioned below.
"""

def estimate(x):
    return x*9 + 3

estimate(36)

"""The above logic is so simple(atleast for me), but what if the logic is too complex, 
what if instead of single input if we need to calculate with more inputs to derive the final output.
<br>
Can we identify the function or logic to calculate the output value?
<br>
Can we write a program to identify the logic?
<br>
Can we build a brain that mimics you or me..?
<br>
Why not, we can build one using artificial intelligence that mimics us(you and me).
<br>
So our expected function is f(x) = 9x + 3 or y = 9x + 3

The above task can be achieved by traditional machine learning algorithms. But in this course we will
build a Neural network model.
<br>
Just think of our brain. Our brain contains lot of nuerons and every neuron will process some input 
and provides the output to the next nueron or nuerons. Our brain nuerons or interconnected and responsible 
for processing the input for the actions.

We will use tensor flow to build a model to process the above input. We use tensorflow 2.x version
"""

import tensorflow as tf
import numpy as np

"""Define the input and output to train our model. Our tensorflow accepts only the numerical values.
So every input that we provide to the model should be converted to numerical values.
"""

input = np.array([1, 2, 3, 10, 20, 80, 54, 72, 90],  dtype=float)
output = np.array([12, 21, 30, 93, 183, 723, 489, 651, 813],dtype=float)

"""Now we are ready with input and output values to train our model. 
As a first step we will build a small neural network model to understand how the neural network model works.
Every nueron you define in the model will accept the input and process the output.
For example if a neuron receives an input x it calculates the output as
<br>
a = wx + b where as
<br>
<br>a = output
<br>w = weight
<br>b = bias.
<br>Every input is multiplied by a weight(w) and adds the bias.
These weights and bias will be adjusted as we train our model.

Our model structure is as below.
1. Input, Output Values for training.
2. Layer of single nueron
3. Output

In the first step we define the layer that accepts the input and calculates the output`
"""

# layer = tf.keras.layers.Dense(units=1, input_shape=[1])

"""Add the above defined layer to a model. We define the Sequential Model and add the layer by layer
(if we have any multiple layers)
"""

# model = tf.keras.Sequential([layer])

"""We defined the model with layers. No we need to compile our model and tell it how to validate its output
against the actual output. How to finetune itself, we teach the method to rectify itself.
<br>
Loss function - This tell what is the error(difference) value of each predicted output versus the actual output
<br>
Optimier function - Way to adjust the weights and biases. The minimum adjustment might take more time to train the model or overfitting. The large adjustment values may create low accurate models.
<br>
We will discuss more on these parameters going forward.
"""

# model.compile(loss=tf.keras.losses.mean_squared_error,
#              optimizer=tf.keras.optimizers.Adam(0.1))

"""Now we will provide the sample training data and will run the above defined mode to fit the input data."""



"""Here it shows param as 2.
How to calculate the params at each learning layer(will discuss about the learning layers later).
Here it is single neuron it takes only two parameters as weight and bias.
Lets see what are the weights and bias of that single neuron in the layer.
"""

# layer.get_weights()

"""As you see the above function prints the weights and bias. Here the weight is 8.986033 and bias is 3.9599
<br><br>
The single neuron constructed a function on the input as $8.986033 \times input + 3.9599$
<br><br>
If you observe the above equation it is close to our actual function. Here the bias was not adjusted close to 3 but
we see the function is almost same as our actual function. As it is artificial there is always a chance for the error which can be negotiable at this point of time.

Lets make it little complex and add some more dense layer in between. Lets see the accuracy.
Define the 3 layers.
1. Layer1 has 2 neurons accepting the single input
2. Layer2 has 4 neurons accepting the input from the 2 neurons from Layer1
3. Layer3 has single neuron accepts input from 4 neurons from Layer2
"""

layer1 = tf.keras.layers.Dense(units=2, input_shape=[1])
layer2 = tf.keras.layers.Dense(units=4)
layer3 = tf.keras.layers.Dense(units=1)

model = tf.keras.Sequential([layer1, layer2, layer3])
model.compile(loss=tf.keras.losses.mean_squared_error,
             optimizer=tf.keras.optimizers.Adam(0.1))

model.fit(input, output, epochs=1500, verbose=False)

model.predict([36])

layer1.get_weights()

layer2.get_weights()

layer3.get_weights()

history = model.fit(input, output, epochs=1500, verbose=False)

"""Lets plot the loss of our model over the epochs"""

import matplotlib.pyplot as plt
plt.figure()
plt.title("Loss versus Epochs")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.plot(history.history['loss'])
plt.show()

"""From the above plot we can say our model learnt pretty fast upto 125 epochs and after that the loss is almost flat but with consistent difference.
As the epochs increases the loss will decrease. We will discuss on the number of epochs(early stops or finetuning the hyperparamets in the next sessions).

Lets Predict an input which is not part of our training model. 36 is not part of our model training.
"""

model.predict([36])

"""Actual answer is $36 \times 9 +3 = 327$
Looks like our model is doing pretty well.

Like wise we can predict other variables as well
"""

validate_set = [25, 212, 49, 102]

model.predict(validate_set)

"""Actual outputs"""

for val in validate_set:
    print(estimate(val))

"""As we discussed above we defined the Neural network model with single nueron. Lets print the model summary"""

model.summary()

"""The above weigths and biases looks complex but they also yield the better results.

If you see the above results they are much closer than the previous "model".
Adding more layers might increase the accuracy of the model as it is more prune to adjust the weights and biases.
<br>But the more layers make the model complex and thus it is little difficult to understand.

![DNN_Architecture.jpg](attachment:DNN_Architecture.jpg)

![DNN.jpeg](attachment:DNN.jpeg)

The input from Input Layer goes to 2 neurons in Layer1. And the equation is as below.	
w11*x+b11=a11
<br>
w12*x+b12=a12
	
Each output of Layer1 goes to 4 neurons in the Layer2 and the equation is as below.	
w21(a11)+w22(a12)+b21=a21
<br>
w23(a11)+w24(a12)+b22=a22
<br>
w25(a11)+w26(a12)+b23=a23
<br>
w27(a11)+w28(a12)+b24=a24
	
The above output from Layer2 goes to 2 neurons in the Layer3	
w31(a21) +w32(a22)+w33(a23)+w34(a24)+b31=a31(output)
<br>
The above final equation will yield a31=wx+b where the w, b close to 9 and 3	
	
After many calculations the final equation is(It takes lot of time, try when you are free)	
y=9*x+b
"""

model.predict(validate_set)

for val in validate_set:
    print(estimate(val))

model.summary()

"""In the model2 we have total of 7 neurons compared to 1 neuron in the earlier model. After our study
we can say that model2 is giving more accurate results. Thought more neurons makes the model complex
but it might result more accurate result(This statement is not true always).

The above example is a classic representation of Regression problem using Deep Neural Networks.
In the next section we will discuss the Classification Model.
"""

model.save("samplemodel.h5")

